#!/usr/bin/env python3
"""
GitHub Actions Subscription Generator for NekoBox/FlClash
ç”Ÿæˆå¯ç›´æ¥ä½¿ç”¨çš„åœ¨çº¿è®¢é˜…é“¾æ¥
"""

import os
import json
import time
import requests
import base64
import re
import argparse
import random
from datetime import datetime
from urllib.parse import urlparse, quote
import concurrent.futures
import threading

class SubscriptionGenerator:
    def __init__(self, args):
        self.args = args
        self.nodes_file = args.nodes_file
        self.output_dir = args.output_dir
        
        # ä»ç¯å¢ƒå˜é‡æˆ–å‘½ä»¤è¡Œå‚æ•°è·å–åœ¨çº¿è®¢é˜…åœ°å€
        self.subscription_urls = self.get_subscription_urls()
        
        # æµ‹è¯•é…ç½®
        self.timeout = args.timeout
        self.latency_threshold = args.latency_threshold
        self.max_workers = args.workers
        self.test_count = args.test_count
        self.top_n = args.top_n
        
        # æµ‹è¯•URLåˆ—è¡¨
        self.test_urls = [
            {
                'url': 'https://www.gstatic.com/generate_204',
                'name': 'Google Static',
                'expected_status': 204,
                'weight': 1.0
            },
            {
                'url': 'https://httpbin.org/get',
                'name': 'HttpBin', 
                'expected_status': 200,
                'weight': 0.9
            }
        ]
        
        self.results = []
        self.lock = threading.Lock()
        
    def get_subscription_urls(self):
        """ä»ç¯å¢ƒå˜é‡æˆ–å‘½ä»¤è¡Œå‚æ•°è·å–åœ¨çº¿è®¢é˜…åœ°å€"""
        if self.args.subscription:
            urls = [url.strip() for url in self.args.subscription.split('&') if url.strip()]
            print(f"ğŸ“¡ ä»å‘½ä»¤è¡Œå‚æ•°æ‰¾åˆ° {len(urls)} ä¸ªåœ¨çº¿è®¢é˜…åœ°å€")
            return urls
        
        subscription_env = os.getenv('ONLINE_SUBSCRIPTION', '').strip()
        if subscription_env:
            urls = [url.strip() for url in subscription_env.split('&') if url.strip()]
            print(f"ğŸ“¡ ä»ç¯å¢ƒå˜é‡æ‰¾åˆ° {len(urls)} ä¸ªåœ¨çº¿è®¢é˜…åœ°å€")
            return urls
        
        return []
    
    def fetch_online_subscription(self, url):
        """è·å–åœ¨çº¿è®¢é˜…å†…å®¹"""
        try:
            print(f"ğŸ”— è·å–è®¢é˜…: {url}")
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, timeout=15, headers=headers)
            response.raise_for_status()
            
            # å°è¯•Base64è§£ç 
            try:
                content = base64.b64decode(response.text).decode('utf-8')
                print(f"âœ… è®¢é˜…è§£ç æˆåŠŸï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
                return content
            except:
                # å¦‚æœä¸æ˜¯Base64ï¼Œç›´æ¥ä½¿ç”¨åŸå†…å®¹
                print(f"âœ… è®¢é˜…è·å–æˆåŠŸï¼Œé•¿åº¦: {len(response.text)} å­—ç¬¦")
                return response.text
                
        except Exception as e:
            print(f"âŒ è·å–è®¢é˜…å¤±è´¥ [{url}]: {e}")
            return None
    
    def parse_subscription_content(self, content):
        """è§£æè®¢é˜…å†…å®¹"""
        nodes = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            # æ”¯æŒå„ç§ä»£ç†åè®®
            if any(proto in line for proto in ['ss://', 'ssr://', 'vmess://', 'trojan://', 'vless://']):
                node = self.parse_node_line(line)
                if node:
                    nodes.append(node)
                    node['source'] = 'subscription'
        
        return nodes
    
    def load_all_nodes(self):
        """åŠ è½½æ‰€æœ‰èŠ‚ç‚¹ï¼ˆæœ¬åœ°æ–‡ä»¶ + åœ¨çº¿è®¢é˜…ï¼‰"""
        all_nodes = []
        
        # 1. åŠ è½½æœ¬åœ°èŠ‚ç‚¹æ–‡ä»¶
        local_nodes = self.parse_nodes_file()
        for node in local_nodes:
            node['source'] = 'local'
        all_nodes.extend(local_nodes)
        print(f"ğŸ“ æœ¬åœ°èŠ‚ç‚¹: {len(local_nodes)} ä¸ª")
        
        # 2. åŠ è½½åœ¨çº¿è®¢é˜…èŠ‚ç‚¹
        subscription_nodes = []
        for sub_url in self.subscription_urls:
            try:
                content = self.fetch_online_subscription(sub_url)
                if content:
                    nodes = self.parse_subscription_content(content)
                    subscription_nodes.extend(nodes)
                    print(f"ğŸ“¥ ä»è®¢é˜…è·å–èŠ‚ç‚¹: {len(nodes)} ä¸ª")
                    time.sleep(1)
                    
            except Exception as e:
                print(f"âŒ å¤„ç†è®¢é˜…å¤±è´¥ [{sub_url}]: {e}")
        
        all_nodes.extend(subscription_nodes)
        
        # å»é‡
        unique_nodes = []
        seen = set()
        
        for node in all_nodes:
            node_id = node['original']
            if node_id not in seen:
                seen.add(node_id)
                unique_nodes.append(node)
        
        # å¦‚æœæŒ‡å®šäº†æµ‹è¯•æ•°é‡ï¼Œè¿›è¡ŒæŠ½æ ·
        if self.test_count > 0 and len(unique_nodes) > self.test_count:
            print(f"ğŸ”¢ æŠ½æ ·æµ‹è¯•: ä» {len(unique_nodes)} ä¸ªèŠ‚ç‚¹ä¸­éšæœºé€‰æ‹© {self.test_count} ä¸ª")
            unique_nodes = random.sample(unique_nodes, self.test_count)
        
        print(f"ğŸ“Š æ€»èŠ‚ç‚¹æ•°: {len(all_nodes)} â†’ å»é‡å: {len(unique_nodes)} ä¸ª")
        return unique_nodes
    
    def parse_nodes_file(self):
        """è§£æèŠ‚ç‚¹æ–‡ä»¶"""
        nodes = []
        if not os.path.exists(self.nodes_file):
            print(f"âš ï¸ èŠ‚ç‚¹æ–‡ä»¶ {self.nodes_file} ä¸å­˜åœ¨")
            return nodes
            
        try:
            with open(self.nodes_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line or line.startswith('#'):
                        continue
                    
                    node = self.parse_node_line(line)
                    if node:
                        nodes.append(node)
                    else:
                        print(f"âš ï¸ ç¬¬{line_num}è¡Œæ— æ³•è§£æ: {line[:50]}...")
                        
            return nodes
            
        except Exception as e:
            print(f"âŒ è¯»å–èŠ‚ç‚¹æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def parse_node_line(self, line):
        """è§£æå•è¡ŒèŠ‚ç‚¹é…ç½®"""
        line = line.strip()
        
        patterns = [
            {'regex': r'^ssr://([A-Za-z0-9+/=]+)', 'type': 'ssr'},
            {'regex': r'^vmess://([A-Za-z0-9+/=]+)', 'type': 'vmess'},
            {'regex': r'^trojan://([^@]+)@([^:]+):(\d+)', 'type': 'trojan'},
            {'regex': r'^vless://([^@]+)@([^:]+):(\d+)', 'type': 'vless'},
            {'regex': r'^ss://([A-Za-z0-9+/=]+)', 'type': 'ss'}
        ]
        
        for pattern in patterns:
            match = re.match(pattern['regex'], line)
            if match:
                return {
                    'original': line,
                    'type': pattern['type'],
                    'parts': match.groups()
                }
        
        return None
    
    def test_latency(self, node):
        """æµ‹è¯•èŠ‚ç‚¹å»¶è¿Ÿ"""
        test_results = []
        fastest_success = None
        
        for test_url in self.test_urls:
            try:
                start_time = time.time()
                
                response = requests.get(
                    test_url['url'],
                    timeout=8,
                    headers={
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    }
                )
                
                latency = int((time.time() - start_time) * 1000)
                is_success = response.status_code == test_url['expected_status']
                
                test_result = {
                    'url': test_url['name'],
                    'latency': latency,
                    'status': response.status_code,
                    'success': is_success,
                    'weight': test_url['weight']
                }
                
                test_results.append(test_result)
                
                if is_success and latency < self.latency_threshold:
                    if not fastest_success or latency < fastest_success['latency']:
                        fastest_success = test_result
                
                if latency < 100:
                    break
                    
                time.sleep(0.3)
                
            except requests.RequestException as e:
                test_results.append({
                    'url': test_url['name'],
                    'latency': -1,
                    'status': 0,
                    'success': False,
                    'error': str(e),
                    'weight': test_url['weight']
                })
        
        return {
            'fastest_success': fastest_success,
            'all_results': test_results,
            'passed': fastest_success is not None
        }
    
    def test_download_speed(self, node, latency):
        """æµ‹è¯•ä¸‹è½½é€Ÿåº¦"""
        if latency >= 1000:  # å»¶è¿Ÿå¤ªé«˜ä¸æµ‹é€Ÿ
            return 0
            
        print(f"    ğŸš€ å¼€å§‹é€Ÿåº¦æµ‹è¯•ï¼Œå½“å‰å»¶è¿Ÿ: {latency}ms")
        
        # æ ¹æ®å»¶è¿Ÿè°ƒæ•´æµ‹è¯•æ–‡ä»¶å¤§å°
        if latency < 200:
            file_size = 512000  # 500KB
        elif latency < 500:
            file_size = 256000  # 250KB
        else:
            file_size = 102400  # 100KB
        
        speed_test_urls = [
            f'https://httpbin.org/bytes/{file_size}',
            'https://speedtest.ftp.otenet.gr/files/test100k.db'
        ]
        
        for test_url in speed_test_urls:
            try:
                start_time = time.time()
                
                response = requests.get(
                    test_url,
                    timeout=10,
                    stream=True,
                    headers={
                        'User-Agent': 'Mozilla/5.0',
                        'Cache-Control': 'no-cache'
                    }
                )
                response.raise_for_status()
                
                content = b''
                for chunk in response.iter_content(chunk_size=8192):
                    content += chunk
                
                duration = time.time() - start_time
                data_size = len(content)
                
                if data_size > 0 and duration > 0:
                    speed_kbps = (data_size / duration) / 1024
                    
                    print(f"    ğŸ“Š é€Ÿåº¦æµ‹è¯•å®Œæˆ: {speed_kbps:.0f} KB/s")
                    return int(speed_kbps)
                    
            except requests.RequestException:
                continue
                
            time.sleep(0.5)
        
        print("    âš ï¸ æµ‹é€Ÿå¤±è´¥")
        return 0
    
    def get_geo_info(self, ip=None):
        """è·å–åœ°ç†ä½ç½®ä¿¡æ¯"""
        try:
            if not ip:
                ip_response = requests.get('https://httpbin.org/ip', timeout=5)
                if ip_response.status_code == 200:
                    ip_data = ip_response.json()
                    ip = ip_data.get('origin', '').split(',')[0]
            
            if ip:
                geo_response = requests.get(f'http://ip-api.com/json/{ip}', timeout=5)
                if geo_response.status_code == 200:
                    geo_data = geo_response.json()
                    if geo_data.get('status') == 'success':
                        return {
                            'country': geo_data.get('country', 'Unknown'),
                            'city': geo_data.get('city', 'Unknown'),
                            'isp': geo_data.get('isp', 'Unknown'),
                            'ip': ip
                        }
        except:
            pass
        
        return {
            'country': 'Unknown',
            'city': 'Unknown', 
            'isp': 'Unknown',
            'ip': 'Unknown'
        }
    
    def calculate_score(self, latency, speed, success):
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        if latency <= 0:
            return 0
        
        # å»¶è¿Ÿè¯„åˆ†
        if latency < 50:
            latency_score = 100
        elif latency < 100:
            latency_score = 95
        elif latency < 200:
            latency_score = 85
        elif latency < 300:
            latency_score = 75
        elif latency < 500:
            latency_score = 60
        else:
            latency_score = 40
        
        # é€Ÿåº¦è¯„åˆ†
        if speed == 0:
            speed_score = 0
        elif speed > 5000:
            speed_score = 100
        elif speed > 2000:
            speed_score = 90
        elif speed > 1000:
            speed_score = 80
        elif speed > 500:
            speed_score = 70
        elif speed > 100:
            speed_score = 50
        else:
            speed_score = 30
        
        # æˆåŠŸç‡è¯„åˆ†
        success_score = 100 if success else 0
        
        # åŠ æƒè¯„åˆ†
        total_score = (latency_score * 0.6 + speed_score * 0.4 + success_score * 0.2) / 1.2
        return round(total_score, 1)
    
    def test_single_node(self, node, index, total_count):
        """æµ‹è¯•å•ä¸ªèŠ‚ç‚¹"""
        node_id = f"{index+1}/{total_count}"
        print(f"\nğŸ” æµ‹è¯•èŠ‚ç‚¹ {node_id}: {node['type']}èŠ‚ç‚¹")
        
        try:
            # å»¶è¿Ÿæµ‹è¯•
            latency_test = self.test_latency(node)
            
            if not latency_test['passed']:
                print(f"    âŒ æœªé€šè¿‡å»¶è¿Ÿæµ‹è¯•")
                return None
            
            latency = latency_test['fastest_success']['latency']
            print(f"    âœ… å»¶è¿Ÿæµ‹è¯•é€šè¿‡: {latency}ms")
            
            # é€Ÿåº¦æµ‹è¯•
            speed = 0
            if latency < self.latency_threshold:
                speed = self.test_download_speed(node, latency)
            
            # è·å–åœ°ç†ä½ç½®ï¼ˆç®€åŒ–ï¼‰
            geo_info = self.get_geo_info()
            
            # è®¡ç®—è¯„åˆ†
            score = self.calculate_score(latency, speed, latency_test['fastest_success']['success'])
            
            result = {
                'node': node['original'],
                'type': node['type'],
                'latency': latency,
                'speed': speed,
                'country': geo_info['country'],
                'isp': geo_info['isp'],
                'score': score,
                'success': latency_test['fastest_success']['success'],
                'source': node.get('source', 'unknown')
            }
            
            print(f"    ğŸ“Š ç»¼åˆè¯„åˆ†: {score}")
            return result
            
        except Exception as e:
            print(f"    âŒ æµ‹è¯•å¤±è´¥: {e}")
            return None
    
    def run_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹èŠ‚ç‚¹æµ‹è¯•...")
        
        # åŠ è½½æ‰€æœ‰èŠ‚ç‚¹
        nodes = self.load_all_nodes()
        if not nodes:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯æµ‹è¯•çš„èŠ‚ç‚¹")
            return
        
        print(f"ğŸ“Š æ€»å…± {len(nodes)} ä¸ªèŠ‚ç‚¹éœ€è¦æµ‹è¯•\n")
        
        passed_count = 0
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æµ‹è¯•
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_node = {
                executor.submit(self.test_single_node, node, i, len(nodes)): (i, node)
                for i, node in enumerate(nodes)
            }
            
            for future in concurrent.futures.as_completed(future_to_node):
                i, node = future_to_node[future]
                try:
                    result = future.result()
                    if result:
                        with self.lock:
                            self.results.append(result)
                            if result['success']:
                                passed_count += 1
                except Exception as e:
                    print(f"âŒ èŠ‚ç‚¹æµ‹è¯•å¼‚å¸¸: {e}")
        
        # æŒ‰è¯„åˆ†æ’åº
        self.results.sort(key=lambda x: x['score'], reverse=True)
        
        print(f'\nğŸ‰ æµ‹è¯•å®Œæˆ! é€šè¿‡èŠ‚ç‚¹: {passed_count}/{len(nodes)}')
    
    def generate_neko_subscription(self):
        """ç”ŸæˆNekoBox/FlClashå¯ç”¨çš„è®¢é˜…æ–‡ä»¶"""
        print("\nğŸ“¡ ç”Ÿæˆè®¢é˜…æ–‡ä»¶...")
        
        # ç­›é€‰ä¼˜è´¨èŠ‚ç‚¹
        valid_nodes = []
        for result in self.results:
            if (result['success'] and 
                result['score'] > 30 and
                result.get('speed', 0) > 100):
                valid_nodes.append(result)
        
        if not valid_nodes:
            print("âŒ æ²¡æœ‰åˆæ ¼çš„èŠ‚ç‚¹")
            return None
        
        # åªå–å‰Nä¸ª
        valid_nodes = valid_nodes[:self.top_n]
        
        print(f"ğŸ¯ é€‰å–äº† {len(valid_nodes)} ä¸ªä¼˜è´¨èŠ‚ç‚¹")
        
        # ç”Ÿæˆæ ‡å‡†è®¢é˜…æ ¼å¼
        subscription_content = self._create_subscription_content(valid_nodes)
        
        # Base64ç¼–ç 
        encoded_content = base64.b64encode(subscription_content.encode()).decode()
        
        # ä¿å­˜è®¢é˜…æ–‡ä»¶
        os.makedirs(self.output_dir, exist_ok=True)
        
        # 1. åŸå§‹è®¢é˜…æ–‡ä»¶
        sub_file = os.path.join(self.output_dir, 'subscription.txt')
        with open(sub_file, 'w', encoding='utf-8') as f:
            f.write(encoded_content)
        
        # 2. è§£ç åçš„æ–‡ä»¶ï¼ˆæ–¹ä¾¿æŸ¥çœ‹ï¼‰
        decoded_file = os.path.join(self.output_dir, 'subscription_decoded.txt')
        with open(decoded_file, 'w', encoding='utf-8') as f:
            f.write(subscription_content)
        
        # 3. JSONæ ¼å¼ï¼ˆåŒ…å«è¯¦ç»†ä¿¡æ¯ï¼‰
        json_file = os.path.join(self.output_dir, 'subscription_info.json')
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'node_count': len(valid_nodes),
                'nodes': valid_nodes,
                'subscription_base64': encoded_content
            }, f, indent=2, ensure_ascii=False)
        
        # 4. ç”Ÿæˆä½¿ç”¨è¯´æ˜
        self._generate_usage_guide(valid_nodes, encoded_content)
        
        return encoded_content
    
    def _create_subscription_content(self, nodes):
        """åˆ›å»ºè®¢é˜…å†…å®¹"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        content_lines = [
            "# ğŸš€ NekoBox/FlClash ä¼˜é€‰è®¢é˜…",
            f"# ç”Ÿæˆæ—¶é—´: {timestamp}",
            f"# èŠ‚ç‚¹æ•°é‡: {len(nodes)}",
            f"# å¹³å‡å»¶è¿Ÿ: {sum(n['latency'] for n in nodes)/len(nodes):.0f}ms",
            f"# å¹³å‡é€Ÿåº¦: {sum(n.get('speed', 0) for n in nodes)/len(nodes)/1024:.1f} MB/s",
            f"# å¹³å‡è¯„åˆ†: {sum(n['score'] for n in nodes)/len(nodes):.1f}",
            ""
        ]
        
        # æ·»åŠ èŠ‚ç‚¹
        for i, node in enumerate(nodes, 1):
            speed_mbps = node.get('speed', 0) / 1024
            content_lines.append(f"# {i}. {node['country']} | {node['latency']}ms | {speed_mbps:.1f}MB/s | {node['score']}åˆ†")
            content_lines.append(node['node'])
            content_lines.append("")
        
        return '\n'.join(content_lines)
    
    def _generate_usage_guide(self, nodes, encoded_content):
        """ç”Ÿæˆä½¿ç”¨æŒ‡å—"""
        guide = f"""# ğŸ¯ NekoBox/FlClash è®¢é˜…ä½¿ç”¨æŒ‡å—

## ğŸ“Š è®¢é˜…ä¿¡æ¯
- ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- èŠ‚ç‚¹æ•°é‡: {len(nodes)} ä¸ª
- æœ€ä½³å»¶è¿Ÿ: {min(n['latency'] for n in nodes)}ms
- å¹³å‡é€Ÿåº¦: {sum(n.get('speed', 0) for n in nodes)/len(nodes)/1024:.1f} MB/s
- å¹³å‡è¯„åˆ†: {sum(n['score'] for n in nodes)/len(nodes):.1f}

## ğŸ“± ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1: ç›´æ¥ä½¿ç”¨ï¼ˆæ¨èï¼‰
è®¢é˜…é“¾æ¥ç›´æ¥å¤åˆ¶ä»¥ä¸‹å†…å®¹ï¼š
{substitution.txtæ–‡ä»¶çš„å†…å®¹é¢„è§ˆ}

æˆ–è€…ä½¿ç”¨æ–‡ä»¶è·¯å¾„ï¼š
file://{os.path.abspath(os.path.join(self.output_dir, 'subscription.txt'))}

### æ–¹æ³•2: åœ¨çº¿éƒ¨ç½²
1. å°† subscription.txt ä¸Šä¼ åˆ°ä»¥ä¸‹ä»»ä¸€å¹³å°ï¼š
   - GitHub Gist (https://gist.github.com)
   - Pastebin (https://pastebin.com)
   - ä¸ªäººæœåŠ¡å™¨
2. è·å–æ–‡ä»¶çš„åŸå§‹é“¾æ¥ï¼ˆRaw URLï¼‰
3. åœ¨NekoBox/FlClashä¸­æ·»åŠ è¯¥é“¾æ¥ä½œä¸ºè®¢é˜…

### æ–¹æ³•3: å¿«é€Ÿéƒ¨ç½²åˆ°å…è´¹å¹³å°

#### GitHub Pages:
1. åˆ›å»ºæ–°ä»“åº“
2. ä¸Šä¼  subscription.txt
3. å¼€å¯Settings â†’ Pages
4. è®¢é˜…é“¾æ¥: https://[ç”¨æˆ·å].github.io/[ä»“åº“å]/subscription.txt

#### Vercel:
1. æ³¨å†Œ Vercel (vercel.com)
2. åˆ›å»ºæ–°é¡¹ç›®ï¼Œä¸Šä¼  subscription.txt
3. éƒ¨ç½²
4. è®¢é˜…é“¾æ¥: https://[é¡¹ç›®å].vercel.app/subscription.txt

## ğŸ“‹ èŠ‚ç‚¹è¯¦æƒ…
"""
        
        for i, node in enumerate(nodes, 1):
            speed_mbps = node.get('speed', 0) / 1024
            guide += f"{i}. {node['country']} - {node['latency']}ms - {speed_mbps:.1f}MB/s - {node['score']}åˆ† ({node['type']})\n"
        
        guide += "\n## âš™ï¸ å®¢æˆ·ç«¯é…ç½®å»ºè®®\n"
        guide += "1. NekoBox: æ·»åŠ è®¢é˜… â†’ ç²˜è´´é“¾æ¥ â†’ è‡ªåŠ¨æ›´æ–°\n"
        guide += "2. FlClash: è®¢é˜…ç®¡ç† â†’ æ·»åŠ  â†’ ç²˜è´´é“¾æ¥\n"
        guide += "3. å»ºè®®å¼€å¯è‡ªåŠ¨é€‰æ‹©æœ€å¿«èŠ‚ç‚¹\n"
        guide += "4. æ›´æ–°é¢‘ç‡: æ¯6-12å°æ—¶è‡ªåŠ¨æ›´æ–°\n"
        
        guide_file = os.path.join(self.output_dir, 'USAGE.md')
        with open(guide_file, 'w', encoding='utf-8') as f:
            f.write(guide)
        
        # ç”Ÿæˆä¸€é”®éƒ¨ç½²è„šæœ¬
        self._generate_deploy_scripts(nodes)
        
        print(f"ğŸ“– ä½¿ç”¨æŒ‡å—å·²ç”Ÿæˆ: {guide_file}")
    
    def _generate_deploy_scripts(self, nodes):
        """ç”Ÿæˆéƒ¨ç½²è„šæœ¬"""
        
        # 1. Cloudflare Workers è„šæœ¬
        cf_worker_script = f"""// Cloudflare Worker éƒ¨ç½²è®¢é˜…
addEventListener('fetch', event => {{
  event.respondWith(handleRequest(event.request))
}})

const nodes = `{base64.b64encode('\\n'.join([n['node'] for n in nodes]).encode()).decode()}`

async function handleRequest(request) {{
  const url = new URL(request.url)
  
  if (url.pathname === '/subscribe') {{
    return new Response(nodes, {{
      headers: {{
        'Content-Type': 'text/plain;charset=UTF-8',
        'Cache-Control': 'public, max-age=3600',
        'Access-Control-Allow-Origin': '*'
      }}
    }})
  }}
  
  return new Response('NekoBox Subscription Service', {{ status: 200 }})
}}
"""
        
        # 2. Vercel Serverless Function
        vercel_function = f"""// Vercel Function (api/subscribe.js)
module.exports = (req, res) => {{
  const nodes = `{base64.b64encode('\\n'.join([n['node'] for n in nodes]).encode()).decode()}`
  
  res.setHeader('Content-Type', 'text/plain;charset=UTF-8')
  res.setHeader('Cache-Control', 'public, max-age=3600')
  res.setHeader('Access-Control-Allow-Origin', '*')
  res.send(nodes)
}}
"""
        
        # 3. ç®€å•çš„é™æ€HTMLé¡µé¢
        html_page = f"""<!DOCTYPE html>
<html>
<head>
    <title>NekoBox è®¢é˜…æœåŠ¡</title>
    <meta charset="utf-8">
</head>
<body>
    <h1>ğŸš€ NekoBox/FlClash è®¢é˜…æœåŠ¡</h1>
    <p>è®¢é˜…é“¾æ¥: <code id="sub-link">å½“å‰é¡µé¢URL/subscribe</code></p>
    <p>èŠ‚ç‚¹æ•°é‡: {len(nodes)} ä¸ª</p>
    <p>æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    <button onclick="copyLink()">å¤åˆ¶è®¢é˜…é“¾æ¥</button>
    
    <script>
    function copyLink() {{
        const link = window.location.origin + '/subscribe';
        navigator.clipboard.writeText(link);
        alert('è®¢é˜…é“¾æ¥å·²å¤åˆ¶: ' + link);
    }}
    </script>
</body>
</html>
"""
        
        # ä¿å­˜è„šæœ¬
        scripts_dir = os.path.join(self.output_dir, 'deploy_scripts')
        os.makedirs(scripts_dir, exist_ok=True)
        
        with open(os.path.join(scripts_dir, 'cloudflare_worker.js'), 'w', encoding='utf-8') as f:
            f.write(cf_worker_script)
        
        with open(os.path.join(scripts_dir, 'vercel_function.js'), 'w', encoding='utf-8') as f:
            f.write(vercel_function)
        
        with open(os.path.join(scripts_dir, 'index.html'), 'w', encoding='utf-8') as f:
            f.write(html_page)
        
        print(f"âš™ï¸ éƒ¨ç½²è„šæœ¬å·²ç”Ÿæˆåˆ°: {scripts_dir}")
    
    def generate_clash_config(self):
        """å¯é€‰ï¼šç”ŸæˆClashé…ç½®æ–‡ä»¶"""
        try:
            import yaml
            
            # ç­›é€‰èŠ‚ç‚¹
            valid_nodes = [n for n in self.results if n['success'] and n['score'] > 30]
            valid_nodes = valid_nodes[:self.top_n]
            
            if not valid_nodes:
                return
            
            clash_config = {
                'port': 7890,
                'socks-port': 7891,
                'allow-lan': False,
                'mode': 'rule',
                'log-level': 'info',
                'proxies': [],
                'proxy-groups': [
                    {
                        'name': 'ğŸš€ è‡ªåŠ¨é€‰æ‹©',
                        'type': 'url-test',
                        'proxies': [],
                        'url': 'http://www.gstatic.com/generate_204',
                        'interval': 300
                    }
                ],
                'rules': [
                    'DOMAIN-SUFFIX,google.com,ğŸš€ è‡ªåŠ¨é€‰æ‹©',
                    'GEOIP,CN,DIRECT',
                    'MATCH,ğŸš€ è‡ªåŠ¨é€‰æ‹©'
                ]
            }
            
            # è§£æèŠ‚ç‚¹
            for i, node in enumerate(valid_nodes):
                try:
                    proxy = self._parse_node_to_clash(node['node'])
                    if proxy:
                        # æ·»åŠ è¯„åˆ†ä¿¡æ¯åˆ°åç§°
                        speed_mbps = node.get('speed', 0) / 1024
                        proxy['name'] = f"{i+1}.{node['country'][:2]}â†”{node['latency']}msâ†”{speed_mbps:.0f}M"
                        
                        clash_config['proxies'].append(proxy)
                        clash_config['proxy-groups'][0]['proxies'].append(proxy['name'])
                except:
                    continue
            
            if clash_config['proxies']:
                clash_file = os.path.join(self.output_dir, 'clash_config.yaml')
                with open(clash_file, 'w', encoding='utf-8') as f:
                    yaml.dump(clash_config, f, allow_unicode=True)
                print(f"âœ… Clashé…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {clash_file}")
                
        except ImportError:
            print("âš ï¸ éœ€è¦å®‰è£…PyYAMLæ¥ç”ŸæˆClashé…ç½®: pip install pyyaml")
        except Exception as e:
            print(f"âŒ ç”ŸæˆClashé…ç½®å¤±è´¥: {e}")
    
    def _parse_node_to_clash(self, node_str):
        """è§£æèŠ‚ç‚¹ä¸ºClashæ ¼å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        if node_str.startswith('ss://'):
            return self._parse_ss_clash(node_str)
        elif node_str.startswith('vmess://'):
            return self._parse_vmess_clash(node_str)
        elif node_str.startswith('trojan://'):
            return self._parse_trojan_clash(node_str)
        return None
    
    def _parse_ss_clash(self, node_str):
        """è§£æSSèŠ‚ç‚¹"""
        try:
            encoded = node_str[5:]
            
            if '@' in encoded:
                method_password, server_port = encoded.split('@')
                if ':' in method_password:
                    method, password = method_password.split(':', 1)
                else:
                    decoded_mp = base64.b64decode(method_password + '==').decode()
                    method, password = decoded_mp.split(':', 1)
                server, port = server_port.split(':')
            else:
                decoded = base64.b64decode(encoded + '==').decode()
                if '@' in decoded:
                    method_password, server_port = decoded.split('@')
                    method, password = method_password.split(':', 1)
                else:
                    method, password, server_port = decoded.split(':', 2)
                server, port = server_port.rsplit(':', 1)
            
            return {
                'name': f"SS-{server}",
                'type': 'ss',
                'server': server,
                'port': int(port),
                'cipher': method,
                'password': password
            }
        except:
            return None
    
    def _parse_vmess_clash(self, node_str):
        """è§£æVMessèŠ‚ç‚¹"""
        try:
            encoded = node_str[8:]
            decoded = base64.b64decode(encoded + '==').decode()
            config = json.loads(decoded)
            
            return {
                'name': f"VMess-{config.get('ps', config.get('add'))}",
                'type': 'vmess',
                'server': config.get('add'),
                'port': int(config.get('port')),
                'uuid': config.get('id'),
                'alterId': int(config.get('aid', 0)),
                'cipher': 'auto',
                'network': config.get('net', 'tcp')
            }
        except:
            return None
    
    def _parse_trojan_clash(self, node_str):
        """è§£æTrojanèŠ‚ç‚¹"""
        try:
            parsed = urlparse(node_str)
            password = parsed.username
            server = parsed.hostname
            port = parsed.port
            
            return {
                'name': f"Trojan-{server}",
                'type': 'trojan',
                'server': server,
                'port': port,
                'password': password
            }
        except:
            return None

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("NekoBox/FlClash è®¢é˜…ç”Ÿæˆå™¨")
    print("ç”Ÿæˆå¯ç›´æ¥ä½¿ç”¨çš„åœ¨çº¿è®¢é˜…é“¾æ¥")
    print("=" * 60)
    
    parser = argparse.ArgumentParser(description='ç”ŸæˆNekoBox/FlClashè®¢é˜…')
    
    # è®¢é˜…ç›¸å…³
    parser.add_argument('--subscription', '-s', 
                       help='åœ¨çº¿è®¢é˜…åœ°å€ï¼Œå¤šä¸ªç”¨&åˆ†éš”')
    
    # æµ‹è¯•å‚æ•°
    parser.add_argument('--workers', '-w', type=int, default=3,
                       help='å¹¶å‘å·¥ä½œçº¿ç¨‹æ•° (é»˜è®¤: 3)')
    parser.add_argument('--timeout', '-t', type=int, default=10,
                       help='è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) (é»˜è®¤: 10)')
    parser.add_argument('--latency-threshold', '-l', type=int, default=2000,
                       help='å»¶è¿Ÿé˜ˆå€¼(æ¯«ç§’) (é»˜è®¤: 2000)')
    parser.add_argument('--test-count', '-n', type=int, default=0,
                       help='æµ‹è¯•èŠ‚ç‚¹æ•°é‡ï¼Œ0è¡¨ç¤ºæµ‹è¯•æ‰€æœ‰ (é»˜è®¤: 0)')
    parser.add_argument('--top-n', type=int, default=15,
                       help='é€‰å–æœ€ä½³èŠ‚ç‚¹çš„æ•°é‡ (é»˜è®¤: 15)')
    
    # æ–‡ä»¶è·¯å¾„
    parser.add_argument('--nodes-file', '-i', default='Nodes',
                       help='è¾“å…¥èŠ‚ç‚¹æ–‡ä»¶è·¯å¾„ (é»˜è®¤: Nodes)')
    parser.add_argument('--output-dir', '-o', default='subscription',
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: subscription)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = SubscriptionGenerator(args)
    
    # è¿è¡Œæµ‹è¯•
    generator.run_tests()
    
    # ç”Ÿæˆè®¢é˜…
    subscription = generator.generate_neko_subscription()
    
    if subscription:
        print("\n" + "=" * 60)
        print("ğŸ‰ è®¢é˜…ç”ŸæˆæˆåŠŸ!")
        print("=" * 60)
        
        # æ˜¾ç¤ºä½¿ç”¨ä¿¡æ¯
        print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"  ğŸ“„ subscription.txt - Base64è®¢é˜…æ–‡ä»¶ (å¯ç›´æ¥ä½¿ç”¨)")
        print(f"  ğŸ“„ subscription_decoded.txt - è§£ç åçš„æ˜æ–‡")
        print(f"  ğŸ“„ subscription_info.json - è¯¦ç»†èŠ‚ç‚¹ä¿¡æ¯")
        print(f"  ğŸ“„ USAGE.md - ä½¿ç”¨æŒ‡å—")
        print(f"  ğŸ“ deploy_scripts/ - éƒ¨ç½²è„šæœ¬")
        
        print(f"\nğŸ“± ä½¿ç”¨æ–¹æ³•:")
        print(f"  1. å°† subscription.txt ä¸Šä¼ åˆ°å¯è®¿é—®çš„URL")
        print(f"  2. åœ¨NekoBox/FlClashä¸­æ·»åŠ è¯¥URLä½œä¸ºè®¢é˜…")
        print(f"  3. å®¢æˆ·ç«¯ä¼šè‡ªåŠ¨æµ‹è¯•å¹¶é€‰æ‹©æœ€å¿«èŠ‚ç‚¹")
        
        print(f"\nğŸŒ æ¨èéƒ¨ç½²å¹³å°:")
        print(f"  â€¢ GitHub Gist (å…è´¹ã€ç®€å•)")
        print(f"  â€¢ Vercel (å…è´¹ã€è‡ªåŠ¨éƒ¨ç½²)")
        print(f"  â€¢ Cloudflare Workers (å…è´¹ã€å¿«é€Ÿ)")
        print(f"  â€¢ ä¸ªäººæœåŠ¡å™¨")
        
        # å¯é€‰ï¼šç”ŸæˆClashé…ç½®
        print(f"\nâš™ï¸ å¯é€‰åŠŸèƒ½:")
        try:
            import yaml
            generator.generate_clash_config()
        except ImportError:
            print("  è¦ç”ŸæˆClashé…ç½®ï¼Œè¯·å®‰è£…: pip install pyyaml")
        
        print("\n" + "=" * 60)
        
    else:
        print("âŒ è®¢é˜…ç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    main()
