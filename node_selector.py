#!/usr/bin/env python3
"""
GitHub Actions Node Selector for NekoBox/FlClash
è‡ªåŠ¨æµ‹è¯•èŠ‚ç‚¹å»¶è¿Ÿã€é€Ÿåº¦ï¼Œå¹¶ç”Ÿæˆå¯ç›´æ¥ä½¿ç”¨çš„åœ¨çº¿è®¢é˜…
"""

import os
import json
import time
import requests
import base64
import re
import argparse
import random
from datetime import datetime
from urllib.parse import urlparse
import concurrent.futures
import threading

class NodeSelector:
    def __init__(self, args):
        self.nodes_file = args.nodes_file
        self.output_dir = args.output_dir
        
        # å‘½ä»¤è¡Œå‚æ•°
        self.args = args
        
        # ä»ç¯å¢ƒå˜é‡æˆ–å‘½ä»¤è¡Œå‚æ•°è·å–åœ¨çº¿è®¢é˜…åœ°å€
        self.subscription_urls = self.get_subscription_urls()
        
        # æµ‹è¯•é…ç½®
        self.timeout = args.timeout
        self.latency_threshold = args.latency_threshold
        self.max_workers = args.workers
        self.test_count = args.test_count
        self.top_n = args.top_n
        
        # æµ‹è¯•URLåˆ—è¡¨
        self.test_urls = [
            {
                'url': 'https://www.gstatic.com/generate_204',
                'name': 'Google Static',
                'expected_status': 204,
                'weight': 1.0
            },
            {
                'url': 'https://httpbin.org/get',
                'name': 'HttpBin', 
                'expected_status': 200,
                'weight': 0.9
            }
        ]
        
        self.results = []
        self.lock = threading.Lock()
        
    def get_subscription_urls(self):
        """ä»ç¯å¢ƒå˜é‡æˆ–å‘½ä»¤è¡Œå‚æ•°è·å–åœ¨çº¿è®¢é˜…åœ°å€"""
        if self.args.subscription:
            urls = [url.strip() for url in self.args.subscription.split('&') if url.strip()]
            print(f"ğŸ“¡ ä»å‘½ä»¤è¡Œå‚æ•°æ‰¾åˆ° {len(urls)} ä¸ªåœ¨çº¿è®¢é˜…åœ°å€")
            return urls
        
        subscription_env = os.getenv('ONLINE_SUBSCRIPTION', '').strip()
        if subscription_env:
            urls = [url.strip() for url in subscription_env.split('&') if url.strip()]
            print(f"ğŸ“¡ ä»ç¯å¢ƒå˜é‡æ‰¾åˆ° {len(urls)} ä¸ªåœ¨çº¿è®¢é˜…åœ°å€")
            return urls
        
        return []
    
    def fetch_online_subscription(self, url):
        """è·å–åœ¨çº¿è®¢é˜…å†…å®¹"""
        try:
            print(f"ğŸ”— è·å–è®¢é˜…: {url}")
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, timeout=15, headers=headers)
            response.raise_for_status()
            
            try:
                content = base64.b64decode(response.text).decode('utf-8')
                print(f"âœ… è®¢é˜…è§£ç æˆåŠŸï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
                return content
            except:
                print(f"âœ… è®¢é˜…è·å–æˆåŠŸï¼Œé•¿åº¦: {len(response.text)} å­—ç¬¦")
                return response.text
                
        except Exception as e:
            print(f"âŒ è·å–è®¢é˜…å¤±è´¥ [{url}]: {e}")
            return None
    
    def parse_subscription_content(self, content):
        """è§£æè®¢é˜…å†…å®¹"""
        nodes = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            if any(proto in line for proto in ['ss://', 'ssr://', 'vmess://', 'trojan://', 'vless://']):
                node = self.parse_node_line(line)
                if node:
                    nodes.append(node)
                    node['source'] = 'subscription'
        
        return nodes
    
    def load_all_nodes(self):
        """åŠ è½½æ‰€æœ‰èŠ‚ç‚¹ï¼ˆæœ¬åœ°æ–‡ä»¶ + åœ¨çº¿è®¢é˜…ï¼‰"""
        all_nodes = []
        
        # 1. åŠ è½½æœ¬åœ°èŠ‚ç‚¹æ–‡ä»¶
        local_nodes = self.parse_nodes_file()
        for node in local_nodes:
            node['source'] = 'local'
        all_nodes.extend(local_nodes)
        print(f"ğŸ“ æœ¬åœ°èŠ‚ç‚¹: {len(local_nodes)} ä¸ª")
        
        # 2. åŠ è½½åœ¨çº¿è®¢é˜…èŠ‚ç‚¹
        subscription_nodes = []
        for sub_url in self.subscription_urls:
            try:
                content = self.fetch_online_subscription(sub_url)
                if content:
                    nodes = self.parse_subscription_content(content)
                    subscription_nodes.extend(nodes)
                    print(f"ğŸ“¥ ä»è®¢é˜…è·å–èŠ‚ç‚¹: {len(nodes)} ä¸ª")
                    time.sleep(1)
                    
            except Exception as e:
                print(f"âŒ å¤„ç†è®¢é˜…å¤±è´¥ [{sub_url}]: {e}")
        
        all_nodes.extend(subscription_nodes)
        
        # å»é‡
        unique_nodes = []
        seen = set()
        
        for node in all_nodes:
            node_id = node['original']
            if node_id not in seen:
                seen.add(node_id)
                unique_nodes.append(node)
        
        # å¦‚æœæŒ‡å®šäº†æµ‹è¯•æ•°é‡ï¼Œè¿›è¡ŒæŠ½æ ·
        if self.test_count > 0 and len(unique_nodes) > self.test_count:
            print(f"ğŸ”¢ æŠ½æ ·æµ‹è¯•: ä» {len(unique_nodes)} ä¸ªèŠ‚ç‚¹ä¸­éšæœºé€‰æ‹© {self.test_count} ä¸ª")
            unique_nodes = random.sample(unique_nodes, self.test_count)
        
        print(f"ğŸ“Š æ€»èŠ‚ç‚¹æ•°: {len(all_nodes)} â†’ å»é‡å: {len(unique_nodes)} ä¸ª")
        return unique_nodes
    
    def parse_nodes_file(self):
        """è§£æèŠ‚ç‚¹æ–‡ä»¶"""
        nodes = []
        if not os.path.exists(self.nodes_file):
            print(f"âš ï¸ èŠ‚ç‚¹æ–‡ä»¶ {self.nodes_file} ä¸å­˜åœ¨")
            return nodes
            
        try:
            with open(self.nodes_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line or line.startswith('#'):
                        continue
                    
                    node = self.parse_node_line(line)
                    if node:
                        nodes.append(node)
                    else:
                        print(f"âš ï¸ ç¬¬{line_num}è¡Œæ— æ³•è§£æ: {line[:50]}...")
                        
            return nodes
            
        except Exception as e:
            print(f"âŒ è¯»å–èŠ‚ç‚¹æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def parse_node_line(self, line):
        """è§£æå•è¡ŒèŠ‚ç‚¹é…ç½®"""
        line = line.strip()
        
        patterns = [
            {'regex': r'^ssr://([A-Za-z0-9+/=]+)', 'type': 'ssr'},
            {'regex': r'^vmess://([A-Za-z0-9+/=]+)', 'type': 'vmess'},
            {'regex': r'^trojan://([^@]+)@([^:]+):(\d+)', 'type': 'trojan'},
            {'regex': r'^vless://([^@]+)@([^:]+):(\d+)', 'type': 'vless'},
            {'regex': r'^ss://([A-Za-z0-9+/=]+)', 'type': 'ss'}
        ]
        
        for pattern in patterns:
            match = re.match(pattern['regex'], line)
            if match:
                return {
                    'original': line,
                    'type': pattern['type'],
                    'parts': match.groups()
                }
        
        return None
    
    def test_latency(self, node):
        """æµ‹è¯•èŠ‚ç‚¹å»¶è¿Ÿ"""
        test_results = []
        fastest_success = None
        
        for test_url in self.test_urls:
            try:
                start_time = time.time()
                
                response = requests.get(
                    test_url['url'],
                    timeout=8,
                    headers={
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    }
                )
                
                latency = int((time.time() - start_time) * 1000)
                is_success = response.status_code == test_url['expected_status']
                
                test_result = {
                    'url': test_url['name'],
                    'latency': latency,
                    'status': response.status_code,
                    'success': is_success,
                    'weight': test_url['weight']
                }
                
                test_results.append(test_result)
                
                if is_success and latency < self.latency_threshold:
                    if not fastest_success or latency < fastest_success['latency']:
                        fastest_success = test_result
                
                if latency < 100:
                    break
                    
                time.sleep(0.3)
                
            except requests.RequestException as e:
                test_results.append({
                    'url': test_url['name'],
                    'latency': -1,
                    'status': 0,
                    'success': False,
                    'error': str(e),
                    'weight': test_url['weight']
                })
        
        return {
            'fastest_success': fastest_success,
            'all_results': test_results,
            'passed': fastest_success is not None
        }
    
    def test_download_speed(self, node, latency):
        """æµ‹è¯•ä¸‹è½½é€Ÿåº¦"""
        if latency >= 1000:
            return 0
            
        print(f"    ğŸš€ å¼€å§‹é€Ÿåº¦æµ‹è¯•ï¼Œå½“å‰å»¶è¿Ÿ: {latency}ms")
        
        if latency < 200:
            file_size = 512000
        elif latency < 500:
            file_size = 256000
        else:
            file_size = 102400
        
        speed_test_urls = [
            f'https://httpbin.org/bytes/{file_size}',
            'https://speedtest.ftp.otenet.gr/files/test100k.db'
        ]
        
        for test_url in speed_test_urls:
            try:
                start_time = time.time()
                
                response = requests.get(
                    test_url,
                    timeout=10,
                    stream=True,
                    headers={
                        'User-Agent': 'Mozilla/5.0',
                        'Cache-Control': 'no-cache'
                    }
                )
                response.raise_for_status()
                
                content = b''
                for chunk in response.iter_content(chunk_size=8192):
                    content += chunk
                
                duration = time.time() - start_time
                data_size = len(content)
                
                if data_size > 0 and duration > 0:
                    speed_kbps = (data_size / duration) / 1024
                    
                    print(f"    ğŸ“Š é€Ÿåº¦æµ‹è¯•å®Œæˆ: {speed_kbps:.0f} KB/s")
                    return int(speed_kbps)
                    
            except requests.RequestException:
                continue
                
            time.sleep(0.5)
        
        print("    âš ï¸ æµ‹é€Ÿå¤±è´¥")
        return 0
    
    def get_geo_info(self, ip=None):
        """è·å–åœ°ç†ä½ç½®ä¿¡æ¯"""
        try:
            if not ip:
                ip_response = requests.get('https://httpbin.org/ip', timeout=5)
                if ip_response.status_code == 200:
                    ip_data = ip_response.json()
                    ip = ip_data.get('origin', '').split(',')[0]
            
            if ip:
                geo_response = requests.get(f'http://ip-api.com/json/{ip}', timeout=5)
                if geo_response.status_code == 200:
                    geo_data = geo_response.json()
                    if geo_data.get('status') == 'success':
                        return {
                            'country': geo_data.get('country', 'Unknown'),
                            'city': geo_data.get('city', 'Unknown'),
                            'isp': geo_data.get('isp', 'Unknown'),
                            'ip': ip
                        }
        except:
            pass
        
        return {
            'country': 'Unknown',
            'city': 'Unknown', 
            'isp': 'Unknown',
            'ip': 'Unknown'
        }
    
    def calculate_score(self, latency, speed, success):
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        if latency <= 0:
            return 0
        
        if latency < 50:
            latency_score = 100
        elif latency < 100:
            latency_score = 95
        elif latency < 200:
            latency_score = 85
        elif latency < 300:
            latency_score = 75
        elif latency < 500:
            latency_score = 60
        else:
            latency_score = 40
        
        if speed == 0:
            speed_score = 0
        elif speed > 5000:
            speed_score = 100
        elif speed > 2000:
            speed_score = 90
        elif speed > 1000:
            speed_score = 80
        elif speed > 500:
            speed_score = 70
        elif speed > 100:
            speed_score = 50
        else:
            speed_score = 30
        
        success_score = 100 if success else 0
        
        total_score = (latency_score * 0.6 + speed_score * 0.4 + success_score * 0.2) / 1.2
        return round(total_score, 1)
    
    def test_single_node(self, node, index, total_count):
        """æµ‹è¯•å•ä¸ªèŠ‚ç‚¹"""
        node_id = f"{index+1}/{total_count}"
        print(f"\nğŸ” æµ‹è¯•èŠ‚ç‚¹ {node_id}: {node['type']}èŠ‚ç‚¹")
        
        try:
            latency_test = self.test_latency(node)
            
            if not latency_test['passed']:
                print(f"    âŒ æœªé€šè¿‡å»¶è¿Ÿæµ‹è¯•")
                return None
            
            latency = latency_test['fastest_success']['latency']
            print(f"    âœ… å»¶è¿Ÿæµ‹è¯•é€šè¿‡: {latency}ms")
            
            speed = 0
            if latency < self.latency_threshold:
                speed = self.test_download_speed(node, latency)
            
            geo_info = self.get_geo_info()
            
            score = self.calculate_score(latency, speed, latency_test['fastest_success']['success'])
            
            result = {
                'node': node['original'],
                'type': node['type'],
                'latency': latency,
                'speed': speed,
                'country': geo_info['country'],
                'isp': geo_info['isp'],
                'score': score,
                'success': latency_test['fastest_success']['success'],
                'source': node.get('source', 'unknown')
            }
            
            print(f"    ğŸ“Š ç»¼åˆè¯„åˆ†: {score}")
            return result
            
        except Exception as e:
            print(f"    âŒ æµ‹è¯•å¤±è´¥: {e}")
            return None
    
    def run_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹èŠ‚ç‚¹æµ‹è¯•...")
        
        nodes = self.load_all_nodes()
        if not nodes:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯æµ‹è¯•çš„èŠ‚ç‚¹")
            return
        
        print(f"ğŸ“Š æ€»å…± {len(nodes)} ä¸ªèŠ‚ç‚¹éœ€è¦æµ‹è¯•\n")
        
        passed_count = 0
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_node = {
                executor.submit(self.test_single_node, node, i, len(nodes)): (i, node)
                for i, node in enumerate(nodes)
            }
            
            for future in concurrent.futures.as_completed(future_to_node):
                i, node = future_to_node[future]
                try:
                    result = future.result()
                    if result:
                        with self.lock:
                            self.results.append(result)
                            if result['success']:
                                passed_count += 1
                except Exception as e:
                    print(f"âŒ èŠ‚ç‚¹æµ‹è¯•å¼‚å¸¸: {e}")
        
        self.results.sort(key=lambda x: x['score'], reverse=True)
        
        print(f'\nğŸ‰ æµ‹è¯•å®Œæˆ! é€šè¿‡èŠ‚ç‚¹: {passed_count}/{len(nodes)}')
        return True
    
    def generate_subscription(self):
        """ç”ŸæˆNekoBox/FlClashå¯ç”¨çš„è®¢é˜…æ–‡ä»¶"""
        print("\nğŸ“¡ ç”Ÿæˆè®¢é˜…æ–‡ä»¶...")
        
        valid_nodes = []
        for result in self.results:
            if (result['success'] and 
                result['score'] > 30 and
                result.get('speed', 0) > 100):
                valid_nodes.append(result)
        
        if not valid_nodes:
            print("âŒ æ²¡æœ‰åˆæ ¼çš„èŠ‚ç‚¹")
            return None
        
        valid_nodes = valid_nodes[:self.top_n]
        
        print(f"ğŸ¯ é€‰å–äº† {len(valid_nodes)} ä¸ªä¼˜è´¨èŠ‚ç‚¹")
        
        subscription_content = self._create_subscription_content(valid_nodes)
        
        encoded_content = base64.b64encode(subscription_content.encode()).decode()
        
        os.makedirs(self.output_dir, exist_ok=True)
        
        sub_file = os.path.join(self.output_dir, 'subscription.txt')
        with open(sub_file, 'w', encoding='utf-8') as f:
            f.write(encoded_content)
        
        decoded_file = os.path.join(self.output_dir, 'subscription_decoded.txt')
        with open(decoded_file, 'w', encoding='utf-8') as f:
            f.write(subscription_content)
        
        json_file = os.path.join(self.output_dir, 'subscription_info.json')
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'node_count': len(valid_nodes),
                'nodes': valid_nodes,
                'subscription_base64': encoded_content
            }, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆä½¿ç”¨æŒ‡å—ï¼ˆä¸ä½¿ç”¨f-stringåŒ…å«å¤æ‚è¡¨è¾¾å¼ï¼‰
        self._generate_usage_guide(valid_nodes, sub_file)
        
        return encoded_content
    
    def _create_subscription_content(self, nodes):
        """åˆ›å»ºè®¢é˜…å†…å®¹"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        content_lines = [
            "# ğŸš€ NekoBox/FlClash ä¼˜é€‰è®¢é˜…",
            f"# ç”Ÿæˆæ—¶é—´: {timestamp}",
            f"# èŠ‚ç‚¹æ•°é‡: {len(nodes)}",
            f"# å¹³å‡å»¶è¿Ÿ: {sum(n['latency'] for n in nodes)/len(nodes):.0f}ms",
            f"# å¹³å‡é€Ÿåº¦: {sum(n.get('speed', 0) for n in nodes)/len(nodes)/1024:.1f} MB/s",
            f"# å¹³å‡è¯„åˆ†: {sum(n['score'] for n in nodes)/len(nodes):.1f}",
            ""
        ]
        
        for i, node in enumerate(nodes, 1):
            speed_mbps = node.get('speed', 0) / 1024
            content_lines.append(f"# {i}. {node['country']} | {node['latency']}ms | {speed_mbps:.1f}MB/s | {node['score']}åˆ†")
            content_lines.append(node['node'])
            content_lines.append("")
        
        return '\n'.join(content_lines)
    
    def _generate_usage_guide(self, nodes, sub_file_path):
        """ç”Ÿæˆä½¿ç”¨æŒ‡å—"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        avg_latency = sum(n['latency'] for n in nodes) / len(nodes)
        avg_speed = sum(n.get('speed', 0) for n in nodes) / len(nodes) / 1024
        avg_score = sum(n['score'] for n in nodes) / len(nodes)
        
        # é¿å…åœ¨f-stringä¸­ä½¿ç”¨åæ–œæ 
        file_path_abs = os.path.abspath(sub_file_path)
        file_path_url = "file://" + file_path_abs.replace('\\', '/')
        
        guide = f"""# ğŸ¯ NekoBox/FlClash è®¢é˜…ä½¿ç”¨æŒ‡å—

## ğŸ“Š è®¢é˜…ä¿¡æ¯
- ç”Ÿæˆæ—¶é—´: {timestamp}
- èŠ‚ç‚¹æ•°é‡: {len(nodes)} ä¸ª
- æœ€ä½³å»¶è¿Ÿ: {min(n['latency'] for n in nodes)}ms
- å¹³å‡é€Ÿåº¦: {avg_speed:.1f} MB/s
- å¹³å‡è¯„åˆ†: {avg_score:.1f}

## ğŸ“± ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1: ç›´æ¥ä½¿ç”¨ï¼ˆæ¨èï¼‰
è®¢é˜…é“¾æ¥ç›´æ¥å¤åˆ¶ä»¥ä¸‹å†…å®¹ï¼š
{file_path_abs}

æˆ–è€…ä½¿ç”¨æ–‡ä»¶è·¯å¾„ï¼š
{file_path_url}

### æ–¹æ³•2: åœ¨çº¿éƒ¨ç½²
1. å°† subscription.txt ä¸Šä¼ åˆ°ä»¥ä¸‹ä»»ä¸€å¹³å°ï¼š
   - GitHub Gist (https://gist.github.com)
   - Pastebin (https://pastebin.com)
   - ä¸ªäººæœåŠ¡å™¨
2. è·å–æ–‡ä»¶çš„åŸå§‹é“¾æ¥ï¼ˆRaw URLï¼‰
3. åœ¨NekoBox/FlClashä¸­æ·»åŠ è¯¥é“¾æ¥ä½œä¸ºè®¢é˜…

### æ–¹æ³•3: å¿«é€Ÿéƒ¨ç½²åˆ°å…è´¹å¹³å°

#### GitHub Pages:
1. åˆ›å»ºæ–°ä»“åº“
2. ä¸Šä¼  subscription.txt
3. å¼€å¯Settings â†’ Pages
4. è®¢é˜…é“¾æ¥: https://[ç”¨æˆ·å].github.io/[ä»“åº“å]/subscription.txt

#### Vercel:
1. æ³¨å†Œ Vercel (vercel.com)
2. åˆ›å»ºæ–°é¡¹ç›®ï¼Œä¸Šä¼  subscription.txt
3. éƒ¨ç½²
4. è®¢é˜…é“¾æ¥: https://[é¡¹ç›®å].vercel.app/subscription.txt

## ğŸ“‹ èŠ‚ç‚¹è¯¦æƒ…
"""
        
        for i, node in enumerate(nodes, 1):
            speed_mbps = node.get('speed', 0) / 1024
            guide += f"{i}. {node['country']} - {node['latency']}ms - {speed_mbps:.1f}MB/s - {node['score']}åˆ† ({node['type']})\n"
        
        guide += "\n## âš™ï¸ å®¢æˆ·ç«¯é…ç½®å»ºè®®\n"
        guide += "1. NekoBox: æ·»åŠ è®¢é˜… â†’ ç²˜è´´é“¾æ¥ â†’ è‡ªåŠ¨æ›´æ–°\n"
        guide += "2. FlClash: è®¢é˜…ç®¡ç† â†’ æ·»åŠ  â†’ ç²˜è´´é“¾æ¥\n"
        guide += "3. å»ºè®®å¼€å¯è‡ªåŠ¨é€‰æ‹©æœ€å¿«èŠ‚ç‚¹\n"
        guide += "4. æ›´æ–°é¢‘ç‡: æ¯6-12å°æ—¶è‡ªåŠ¨æ›´æ–°\n"
        
        guide_file = os.path.join(self.output_dir, 'USAGE.md')
        with open(guide_file, 'w', encoding='utf-8') as f:
            f.write(guide)
        
        # ç”Ÿæˆéƒ¨ç½²è„šæœ¬
        self._generate_deploy_scripts(nodes)
        
        print(f"ğŸ“– ä½¿ç”¨æŒ‡å—å·²ç”Ÿæˆ: {guide_file}")
    
    def _generate_deploy_scripts(self, nodes):
        """ç”Ÿæˆéƒ¨ç½²è„šæœ¬"""
        
        nodes_list = '\n'.join([n['node'] for n in nodes])
        encoded_nodes = base64.b64encode(nodes_list.encode()).decode()
        
        cf_worker_script = f"""// Cloudflare Worker éƒ¨ç½²è®¢é˜…
addEventListener('fetch', event => {{
  event.respondWith(handleRequest(event.request))
}})

const nodes = `{encoded_nodes}`

async function handleRequest(request) {{
  const url = new URL(request.url)
  
  if (url.pathname === '/subscribe') {{
    return new Response(nodes, {{
      headers: {{
        'Content-Type': 'text/plain;charset=UTF-8',
        'Cache-Control': 'public, max-age=3600',
        'Access-Control-Allow-Origin': '*'
      }}
    }})
  }}
  
  return new Response('NekoBox Subscription Service', {{ status: 200 }})
}}
"""
        
        vercel_function = f"""// Vercel Function (api/subscribe.js)
module.exports = (req, res) => {{
  const nodes = `{encoded_nodes}`
  
  res.setHeader('Content-Type', 'text/plain;charset=UTF-8')
  res.setHeader('Cache-Control', 'public, max-age=3600')
  res.setHeader('Access-Control-Allow-Origin', '*')
  res.send(nodes)
}}
"""
        
        scripts_dir = os.path.join(self.output_dir, 'deploy_scripts')
        os.makedirs(scripts_dir, exist_ok=True)
        
        with open(os.path.join(scripts_dir, 'cloudflare_worker.js'), 'w', encoding='utf-8') as f:
            f.write(cf_worker_script)
        
        with open(os.path.join(scripts_dir, 'vercel_function.js'), 'w', encoding='utf-8') as f:
            f.write(vercel_function)
        
        print(f"âš™ï¸ éƒ¨ç½²è„šæœ¬å·²ç”Ÿæˆåˆ°: {scripts_dir}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("NekoBox/FlClash è®¢é˜…ç”Ÿæˆå™¨")
    print("ç”Ÿæˆå¯ç›´æ¥ä½¿ç”¨çš„åœ¨çº¿è®¢é˜…é“¾æ¥")
    print("=" * 60)
    
    parser = argparse.ArgumentParser(description='ç”ŸæˆNekoBox/FlClashè®¢é˜…')
    
    parser.add_argument('--subscription', '-s', 
                       help='åœ¨çº¿è®¢é˜…åœ°å€ï¼Œå¤šä¸ªç”¨&åˆ†éš”')
    
    parser.add_argument('--workers', '-w', type=int, default=3,
                       help='å¹¶å‘å·¥ä½œçº¿ç¨‹æ•° (é»˜è®¤: 3)')
    parser.add_argument('--timeout', '-t', type=int, default=10,
                       help='è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) (é»˜è®¤: 10)')
    parser.add_argument('--latency-threshold', '-l', type=int, default=2000,
                       help='å»¶è¿Ÿé˜ˆå€¼(æ¯«ç§’) (é»˜è®¤: 2000)')
    parser.add_argument('--test-count', '-n', type=int, default=0,
                       help='æµ‹è¯•èŠ‚ç‚¹æ•°é‡ï¼Œ0è¡¨ç¤ºæµ‹è¯•æ‰€æœ‰ (é»˜è®¤: 0)')
    parser.add_argument('--top-n', type=int, default=15,
                       help='é€‰å–æœ€ä½³èŠ‚ç‚¹çš„æ•°é‡ (é»˜è®¤: 15)')
    
    parser.add_argument('--nodes-file', '-i', default='Nodes',
                       help='è¾“å…¥èŠ‚ç‚¹æ–‡ä»¶è·¯å¾„ (é»˜è®¤: Nodes)')
    parser.add_argument('--output-dir', '-o', default='subscription',
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: subscription)')
    
    args = parser.parse_args()
    
    selector = NodeSelector(args)
    
    if not selector.run_tests():
        print("âŒ æµ‹è¯•å¤±è´¥")
        return
    
    subscription = selector.generate_subscription()
    
    if subscription:
        print("\n" + "=" * 60)
        print("ğŸ‰ è®¢é˜…ç”ŸæˆæˆåŠŸ!")
        print("=" * 60)
        
        print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"  ğŸ“„ subscription.txt - Base64è®¢é˜…æ–‡ä»¶ (å¯ç›´æ¥ä½¿ç”¨)")
        print(f"  ğŸ“„ subscription_decoded.txt - è§£ç åçš„æ˜æ–‡")
        print(f"  ğŸ“„ subscription_info.json - è¯¦ç»†èŠ‚ç‚¹ä¿¡æ¯")
        print(f"  ğŸ“„ USAGE.md - ä½¿ç”¨æŒ‡å—")
        print(f"  ğŸ“ deploy_scripts/ - éƒ¨ç½²è„šæœ¬")
        
        print(f"\nğŸ“± ä½¿ç”¨æ–¹æ³•:")
        print(f"  1. å°† subscription.txt ä¸Šä¼ åˆ°å¯è®¿é—®çš„URL")
        print(f"  2. åœ¨NekoBox/FlClashä¸­æ·»åŠ è¯¥URLä½œä¸ºè®¢é˜…")
        print(f"  3. å®¢æˆ·ç«¯ä¼šè‡ªåŠ¨æµ‹è¯•å¹¶é€‰æ‹©æœ€å¿«èŠ‚ç‚¹")
        
        print(f"\nğŸŒ æ¨èéƒ¨ç½²å¹³å°:")
        print(f"  â€¢ GitHub Gist (å…è´¹ã€ç®€å•)")
        print(f"  â€¢ Vercel (å…è´¹ã€è‡ªåŠ¨éƒ¨ç½²)")
        print(f"  â€¢ Cloudflare Workers (å…è´¹ã€å¿«é€Ÿ)")
        print(f"  â€¢ ä¸ªäººæœåŠ¡å™¨")
        
        print("\n" + "=" * 60)
        
    else:
        print("âŒ è®¢é˜…ç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    main()
